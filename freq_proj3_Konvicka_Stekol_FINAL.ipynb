{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Frequentist Machine Learning, Project 3**\n",
        "### **Anna Konvicka and David Stekol**\n",
        "Re-implement the example in section 7.10.2 using any simple, out of the box classifier (like K nearest neighbors from sci-kit). Reproduce the results for the incorrect and correct way of doing cross-validation.\n"
      ],
      "metadata": {
        "id": "hss49_pmZA3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "mhU7hpwfZEnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data generation, 50 labels, 5000 predictors (gaussian), error rate=50%, \n",
        "\n",
        "classes = np.round(np.random.rand(50))    # Assign classes/labels (50% in each)\n",
        "predictors = np.random.normal(loc=0, scale=1, size=(50,5000))\n"
      ],
      "metadata": {
        "id": "vAtblVOfdR-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wrong and Bad\n",
        "\n",
        "From textbook: \n",
        "1. Screen the predictors: find a subset of \"good\" predictors that show fairly strong (univariate) correlation with the class labels\n",
        "2. Using the above subset of predictors, build a multivariate classifier\n",
        "3. Use cross-validation to estimate the unknown tuning parameters and to estimate the prediction error of the final model"
      ],
      "metadata": {
        "id": "XrPc9W4WOKqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1\n",
        "\n",
        "corrs = np.corrcoef(predictors, classes, rowvar=False)[:-1][:,-1]\n",
        "\n",
        "# sort and find most correlated \n",
        "corrs_sorted = sorted(range(len(corrs)), key=lambda x:corrs[x], reverse=True) # check this if errors (lambda key, idk why tf)\n",
        "hundred_most = corrs_sorted[:100]   # returns indices of most highly correlated predictors\n",
        "top_predictors = predictors[:, hundred_most]"
      ],
      "metadata": {
        "id": "d3xuRNkCm7pG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEPS 2, 3\n",
        "\n",
        "  # from sklearn kfold doc https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html \n",
        "\n",
        "kfolds = KFold(n_splits=50, shuffle=True)\n",
        "bad_correctnesses = []\n",
        "\n",
        "for train_index, test_index in kfolds.split(top_predictors):\n",
        "  x_train, x_test = top_predictors[train_index], top_predictors[test_index]\n",
        "  y_train, y_test = classes[train_index], classes[test_index]\n",
        "\n",
        "  neigh = KNeighborsClassifier(n_neighbors=1)   # from KNeighborsClassifier doc\n",
        "  neigh.fit(x_train, y_train)\n",
        "\n",
        "  predictions = neigh.predict(x_test)\n",
        "  correctness = (sum(predictions == y_test)/(len(y_test)))\n",
        "  bad_correctnesses.append(correctness)\n",
        "\n",
        "# RESULTS\n",
        "bad_proportion_correct = np.mean(bad_correctnesses)\n",
        "print(\"CV error rate: \", (1-bad_proportion_correct)*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzaGgiytTCHB",
        "outputId": "9df3cd31-4a68-4ad3-8269-13ff0b16b1d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV error rate:  4.0000000000000036 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sane and Reasonable\n",
        "\n",
        "From textbook:\n",
        "1. Divide the samples into K cross-validation folds at random\n",
        "2. For each fold:\n",
        "\n",
        "  a. Find a subset of \"good\" predictors using all samples except those in fold K\n",
        "\n",
        "  b. Build a multivariate classifier with these predictors \n",
        "\n",
        "  c. Use the classifier to predict the class labels in fold K"
      ],
      "metadata": {
        "id": "g8-MWbgthmMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfolds = KFold(n_splits=50, shuffle=True)     # do I need to do this again? Probably doesn't hurt \n",
        "good_correctnesses = []\n",
        "\n",
        "for train_index, test_index in kfolds.split(top_predictors):\n",
        "  corrs = np.corrcoef(predictors[train_index], classes[train_index], rowvar=False)[:,-1][:-1]\n",
        "  hundred_most = sorted(range(len(corrs)), key=lambda x:corrs[x], reverse=True)[:100]\n",
        "  top_predictors = predictors[:, hundred_most]\n",
        "\n",
        "  x_train, x_test = top_predictors[train_index], top_predictors[test_index]\n",
        "  y_train, y_test = classes[train_index], classes[test_index]\n",
        "\n",
        "  neigh = KNeighborsClassifier(n_neighbors=1)\n",
        "  neigh.fit(x_train, y_train)\n",
        "\n",
        "  predictions = neigh.predict(x_test)\n",
        "  correctness = (sum(predictions == y_test)/(len(y_test)))\n",
        "  good_correctnesses.append(correctness)\n",
        "\n",
        "# RESULTS\n",
        "good_proportion_correct = np.mean(good_correctnesses)\n",
        "print(\"CV error rate: \", (1-good_proportion_correct)*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf5VAWS2iKi6",
        "outputId": "2f8c7468-f214-46d2-e989-4d84bac2a620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV error rate:  56.00000000000001 %\n"
          ]
        }
      ]
    }
  ]
}